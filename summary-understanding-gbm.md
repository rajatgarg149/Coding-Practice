`Gradient Boosting Machines` : An ensemble of **sequentially** built **weak** predictors.

**Why sequential?** - to focus more on mistakes made by predecessor

**Why weak?** - strong predictors generally learn most of the information and the error(remaining information) consists of noise, whereas weak predictors partially learn the information and hence, the successor predictor has scope of learning more information.
